\def\DevnagVersion{2.15}\documentclass[12pt]{article}
\usepackage{devanagari}
\usepackage{cite}
\usepackage{pstricks}
\usepackage{pst-node}
\usepackage{pst-coil}
\usepackage{pst-rel-points}
\usepackage{graphics}
\usepackage{epsfig}
\usepackage{verbatim, hyperref, color}
\usepackage{float}
\usepackage[margin=3cm]{geometry}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\setlength{\parindent}{0pt}
\setlength{\parskip}{0.2cm}
\topskip 0.0in

\title{Handling Anaphoras in multiple languages in the framework of Geometry Constructions}
\author{Jeetesh Mangwani \& Pankaj Prateek\\
	Advisor: Dr. Amitabh Mukherjee\\
        Dept. of Computer Science and Engineering\\
	Indian Institute of Technology, Kanpur, India\\
	\{jeeteshm, pratikkr, amit\} @ cse.iitk.ac.in}
\date{April 17, 2014}

\begin{document}
\maketitle
\begin{center}{\b \em ABSTRACT}\end{center}
{\em In this project, we take up the problem of handling anaphora in multiple languages in the context of a language-independent interpreter for drawing geometric diagrams. We focus on ruler and compass based construction problems. We start with use cases and motivations on why such a system would be useful and what places deploying it would be fruitful. We give a brief tabulated summary review of related research work done on geometry related problems and point out the common trait that they lack the ability to decipher any problem/constraint expressed in a natural language. We, then, move to describe the design of the interpreter and the usage of cross-lingual technique to provide language-independent interpretation ability. We briefly mention how is the alignment model utilised to realize the powerful translation feature. This is followed by the results obtained, difficulties faced and future work.}

\section{Objective}
To design and implement interpreter that
\begin{itemize}
	\item is language-independent (works for English, Hindi at present)
	\item Receives steps for a geometric construction as input e.g. "Draw a line segment AB of length 4 cm", "{\dn k\?{\qva}\qb{d}} B {\dn aOr E/>yA} 5 {\dn s\?mF l\?kr ek cAp KF{\qva}Ece jo phl\? KF{\qva}cF cAp ko} C {\dn pr kAVtA ho}" etc
  \item is capable of handling anaphoras  
	\item Outputs the geometric figure obtained on executing the given sequence of steps 
\end{itemize}

\section{Introduction}
It is often the case that students, teachers, architects and artists need to draw complex diagrams manually using simple geometric instruments like ruler, compass, set squares, dividers etc. This demands labor, time as well as expertise. Resorting to sophisticated graphics applications requires knowhow of application-specific details as well as expertise in coordinating hand micro-movements.\\

In order to save these resources required in drawing geometric diagrams as well as to reduce dependence on complex graphics applications, this project introduces an interpreter for diagram construction steps expressed in a suitable natural language. This not only simplifies the construction, but also leads to easily understood natural language `programs'.\\

\section{Related work}
One of the most common techniques today to perform effective parsing is to use Part-of-Speech tagged language banks. Only few languages (about 8-10 of the 600+ languages in wide use) have the privilege of being resource-rich in the sense of having Penn-tree banks and other large-sized standardised corpus. An important observation is that fixed grammars, POS tags etc used in traditional parsers are not always the best way to break up a language. Taking a note of these shortcomings, we take a statistical approach to learn a language.\\

There has been a significant amount of work done on solving geometry construction problems. Gulwani et. al. \cite{gulwani2011synthesizing} propose a method that uses goal-based heuristic to simulate backward deduction to solve a problem expressed in a predefined logical construct. Schreck et. al. \cite{schreck2012geometric} talk about the same problem but use CAD methods to deal with constraints. At the same time, Itzhaky et. al. \cite{itzhaky2012solving} use the number of nondeterministic choices as a measure of a good solution. Ahmed, Umair et. al. \cite{ahmed2012can} look more into using domain-specific measures to minimize parser errors and augment the geometry problem solver, GeoSynth. All these papers have provided us with valuable insights into selecting important and expressive constructs for our intermediate language.

We summarize our observations in terms of following 3 parameters:
\begin{itemize}
\item Uses other linguistic/domain knowledge
\item Assumes linguistic cues are already translated into logical forms
\item Uses Parse knowledge
\end{itemize}

\begin{table}[H]
\smallskip
\begin{center}
\begin{tabular}{p{0.35\textwidth}p{0.20\textwidth}p{0.20\textwidth}p{0.20\textwidth}}
\hline
\bf{\small Paper} & \bf{\small Uses other linguistic/domain knowledge} & \bf{\small Assumes linguistic clues already traslated into logical forms} & \bf{\small Uses parse knowledge}\\[0.2cm]\hline
Geometric Construction Problem Solving in Computer-Aided Learning\cite{schreck2012geometric} & \texttt{YES} & \texttt{YES} & \texttt{NA}\\\\
Synthesizing geometry constructions\cite{gulwani2011synthesizing} & \texttt{YES} & \texttt{YES} & \texttt{NA}\\\\
Solving geometry problems using a combination of symbolic and numerical reasoning\cite{itzhaky2012solving} & \texttt{YES} & \texttt{YES} & \texttt{NA}\\\\
Can modern statistical parsers lead to better natural language understanding for education?\cite{ahmed2012can} & \texttt{YES} & \texttt{NO} & \texttt{YES}\\\\
Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars\cite{zettlemoyer2012learning} & \texttt{YES} & \texttt{NO} & \texttt{YES}\\
\hline
\end{tabular}
\caption{Related Works}
\end{center}
\end{table}

Unlike all previous attempts, we do not assume that the logical forms of the sentences are available, nor we assume the availability of a parser. We use cross-lingual alignment to map the given sentence in natural language to metalanguage. It is therefore applicable to a large range of languages. We demonstrate this for two widely known languages belonging to very different families - Hindi and English.


% \subsection{Learning to map sentences to logical form: Structured classification with probabilistic categorical grammars\cite{zettlemoyer2012learning}}
% 
% \subsection{Geometric Construction Problem Solving in Computer-Aided Learning\cite{schreck2012geometric}}
% 
% \subsection{Synthesizing geometry constructions\cite{gulwani2011synthesizing}}
% 
% \subsection{Can modern statistical parsers lead to better natural language understanding for education?\cite{ahmed2012can}}
% 
% \subsection{Solving geometry problems using a combination of symbolic and numerical reasoning\cite{itzhaky2012solving}}

\section{Design}
The interpreter consists of the following components:
\begin{itemize}
\item Aligner (training)
\item Grammar
\item Natural Language (NL) Interpreter
  \begin{itemize}
    \item NL to Metalanguage Mapper
    \item Heuristics-based Parser
    \item Semantics Analyser
    \item Plotter  
  \end{itemize}
\item Using Context to handle Anaphoras
\end{itemize}

\subsection{Aligner}
Cross-lingual alignment is the heart of the learning mechanism in this project. It is used to obtain mapping/alignment between a natural language and our carefully designed and structured imperative metalanguage, L0. Since this alignment can be obtained for any natural language, the application is scalable to any number of natural languages. This technique is detailed in later sections\\

We have used GIZA++ \cite{och2003systematic} as the cross-lingual aligner. GIZA++ is a statical machine translation toolkit that is used to train IBM Models 1-5 and an HMM word alignment model.\\

\subsection{Grammar}
The grammar has been carefully designed to capture the underlying structure of the conventional (imperative) geometry construction steps. Note that there is a mild constraint on the grammar, which is a direct consequence of the assumption that the parameters of the object to be plotted occur near to parameter name in the input sentence. Hence the rules have been designed such that for each production rule, the leftmost non-terminal guides the search for the remaining non-terminals. [see section on Proximity]

\subsection{Natural Language (NL) Interpreter}

\subsubsection{NL to Metalanguage Mapper}
The interpreter component exploits the alignment model obtained from the Aligner component. Given a sentence expressed in a natural language, we use the alignment model to get the statistically most probable mapping of the NL sentence to a list of words in the language defined by the grammar. This list of words need not conform to a sentence in the language defined by the grammar but still carries some intent of the NL sentence, and hence can be called a partially ordered list of metalanguage words.\\

\subsubsection{Heuristics-based Parser}
At this stage, the parser takes the partially ordered set of words generated in the previous step and tries to map it to a sentence formed by the grammar. This is done by performing a DFS on the grammar tree and trying to fit every token in the set with some grammar terminal. Given any production rule, our DFS-based algorithm recursively expands the leftmost unexpanded nonterminal in the rule; on encountering a terminal, it tries to fit the terminal to some token near its parent's/left sibling's token. The subtrees which are not satisfied are pruned and search resumes with the next available production rule. The search is aided by the following heuristics:
\begin{enumerate}
\item \textbf{Proximity}\label{sec:proximity}\\
Proximity plays an important role in our parsing method e.g. we have assumed that the object that needs to be constructed would be near the ``construct'' word, and the length of a line segment would be near its name. Consider, as an example, "Construct a line segment AB of length 5 cm". Here, using our assumption we start searching for the object to be constructed near the ``construct'' word; it comes out to be the line segment AB. Note that we have to search on both the sides of the keyword (Give a hindi sentence as an example). This assumption is justified by the structure of the sentences in the natural languages, and specifically the geometry construction steps. This reduces the parsing complexity many-fold. As an another example, "Construct a line segment AB such that length of AB is equal to the difference of the length of CD and length of EF". Here, only those parse trees which demand the construction of AB are retained (as AB is nearer to ``construct'' than CD and EF); remaining trees which involve the construction of CD or EF are pruned.

\item \textbf{Type system}\\
The system is implicitly type-defined. For example, consider a statement like  ``Mark a point A on it''. Here ``it'' can be a line, line segment, circle etc. but not a point, as marking a point on a point is not permitted. Also, point pairs like AB would define a line segment or a ray, ABC would define an arc, 'l' would define a line (according to the conventions in the existing geometry texts). The grammar and the semantic analyser together form the type system.

\item \textbf{Validity of the output}\\
The search is also guided by the output produced at this stage. If the output produced seems correct, i.e., it uses most of the tokens in the set and conforms to some sentence generated by the grammar, it is passed to the semantic analyser. The semantic analyser then checks whether the output represents a valid intent to draw, i.e., a valid plottable object can be inferred out of it. If not, the parser tries to correct the parse tree starting from the rightmost leaf; this procedure is repeated until either we obtain something plottable or exhaust all the possibilities.

\end{enumerate}

\subsubsection{Semantics Analyser}
This stage of the parser uses Lex-Yacc to generate a set of primitive objects like points, lines, arcs etc. which need to be plotted in the last input construction step. All coordinates, radii, lengths and angles are resolved in this step. Anaphora are also resolved in this stage. This is detailed in the later sections.

\subsubsection{Plotter}
For each input construction step, the plotter receives a list of primitive objects from the semantic analyser and plots them on the canvas.

\subsection{Using Context to handle Anaphora}
The semantics analyser uses the context (a list of objects which were plotted in the previous construction steps) to resolve the anaphoras. For example,
``Mark a point M on it''.
Here ``it'' would refer to the most recently plotted markable object (objects on which a point can be marked e.g. lines, line segments, arcs, circles etc.). We fetch such markable object from the context to resolve the anaphora.

\section{Cross-Lingual alignment}
Cross-Lingual alignment is a technique to statistically align the words of a given pair of languages. It is close to translating one language into another, without any syntactic or semantic knowledge of any of the languages. As an example, for a pair of langauges, given sufficiently many sentences as illustrated in the table 2, a cross-lingual alignment assigns probabilities to the event that a particular source-language token is mapped to a target-language token.\\

\begin{table}[H]
\smallskip
\begin{center}
\begin{tabular}{p{0.33\textwidth}p{0.33\textwidth}p{0.33\textwidth}}
\hline
\vspace{0.1cm}\bf{English} & \vspace{0.1cm}\bf{Hindi} & \vspace{0.1cm}\bf{Meta Language}\\[0.2cm]\hline
Construct a line AB of length 4 cm & 4 {\dn s\?mF lMbAI kA ek r\?KAK\317wX} AB {\dn KF{\qva}Ece} & \texttt{construct lineSegment AB length 4 cm}\\[0.2cm]
With A as center and radius 3 cm, draw an arc & {\dn k\?{\qva}\qb{d}} A {\dn aOr E/>yA} 3 {\dn s\?mF l\?kr ek cAp KF{\qva}Ece} & \texttt{constrcut arc center A radius 3 cm}\\[0.2cm]
With B as center and radius 5 cm, draw an arc cutting the previously drawn arc at C & {\dn k\?{\qva}\qb{d}} B {\dn aOr E/>yA} 5 {\dn s\?mF l\?kr ek cAp KF{\qva}Ece jo phl\? KF{\qva}cF cAp ko} C {\dn kAVtA ho} & \texttt{construct intersectingArc center C radius 5 cm cuts arc previous at C}\\[0.2cm]
\hline
\end{tabular}
\caption{Sample Corpus}
\end{center}
\end{table}

\begin{table}[H]
\smallskip
\begin{center}
\begin{tabular}{p{0.33\textwidth}p{0.33\textwidth}c}
\hline
\bf{English} & \bf{Meta Language} & \bf{Probability}\\[0.2cm]\hline
Construct & \texttt{construct} & 1.00\\
Line segment & \texttt{lineSegment} & 1.00\\
intersects & \texttt{intersect} & 0.93\\
intersect eachother & \texttt{intersect} & 0.78\\
cut eachother & \texttt{intersect} & 0.87\\
cut & \texttt{cut} & 0.98\\
join & \texttt{join} & 1.00\\
mark & \texttt{mark} & 0.98\\
label & \texttt{mark} & 0.98\\
bisector & \texttt{bisector} & 0.60\\
interior & \texttt{interior} & 0.20\\
exterior & \texttt{exterior} & 0.20\\
\hline
\end{tabular}
\caption{Sample alignment between English and Metalanguage}
\end{center}
\end{table}

\begin{table}[H]
\smallskip
\begin{center}
\begin{tabular}{p{0.25\textwidth}p{0.25\textwidth}c}
\hline
\bf{Hindi} & \bf{Meta Language} & \bf{Probability}\\[0.2cm]\hline
{\dn lgA dFEjy\?} & \texttt{construct} & 0.90\\
{\dn KF{\qva}Ece} & \texttt{construct} & 0.98\\
{\dn rcnA kFEjy\?} & \texttt{construct} & 0.96\\
{\dn bnAiy\?} & \texttt{construct} & 0.98\\
{\dn r\?KAK\317wX} & \texttt{lineSegment} & 1.00\\
{\dn pr-pr \3FEwEtQC\?d} & \texttt{intersect} & 0.98\\
{\dn kAVtA ho} & \texttt{cut} & 0.82\\
{\dn kAV\?} & \texttt{cut} & 0.95\\
{\dn EmlAiy\?} & \texttt{join} & 0.98\\
{\dn joEwy\?} & \texttt{join} & 0.98\\
{\dn a\2Ekt kFEjy\?} & \texttt{mark} & 0.98\\
{\dn mAn lFEjy\?} & \texttt{mark} & 0.98\\
{\dn smE\392wBAjk} & \texttt{bisector} & 0.59\\
{\dn a<y\306wtr} & \texttt{interior} & 0.20\\
{\dn bEhBA\0g} & \texttt{exterior} & 0.20\\
\hline
\end{tabular}
\caption{Sample alignment between Hindi and Metalanguage}
\end{center}
\end{table}

\section{What has been done}
\subsection{Corpus}
The corpus contains around 350 sentences from the geometry construction field in both the languages. These were collected from the NCERT textbooks of standards ${6^{th}}$ to ${9^{th}}$. English-Metalanguage and Hindi-Metalanguage sentence pairs were generated manually which were then used to train the cross lingual alignment software

The corpus has been formatted as follows:\\
For every sentence in natural language, 
\begin{itemize}
\item First line corresponds to the natural language sentence.
\item The second line corresponds to the intended meta langauge sentence.
\item The third line is an empty line.
\end{itemize}
The corpus is available at \cite{corpus}

To get an almost perfect probabilistic map between the parallel corpus, we impose a mild constraint: let the map be from language A to B; we design the corpus such that every word of the language A either maps to exactly one word of language B or to the empty word. Note that this is not necessary. It has been done so as to obtain the best possible map for a given corpus size under corss-lingual alignment. Poorer quality of map leads to considerable increase in the possible translations that the parser would have to parse.

\subsection{Parser}
Suppose the input sentence is "Construct a line segment AB of length 7 cm". Using the English-to-Metalanguage map, we translate this sentence tokenwise to "construct line segment AB length 7 cm" where ``a'' and ``of'' map to empty words. Similarly, for the input sentence ``7 {\dn s\?mF lMbAI kA ek r\?KAK\317wX} AB {\dn KF{\qva}Ece}'', using the Hindi-to-Metalanguage map, we obtain the translation ``7 cm length line segment construct'', where ``{\dn kA}'' and ``{\dn ek}'' map to empty word.\\

For both of these translations, we obtain the same parse tree, which is illustrated below:

\begin{figure}[H]
  \begin{center}
    \includegraphics[scale=0.5]{parsetree.png}
  \end{center}
  \caption{Sample Parse Tree}
  \label{fig:pspic}
\end{figure}
\begin{figure}[H]
  \begin{center}
    \includegraphics[scale=0.5]{workflow.png}
  \end{center}
  \caption{Work Flow}
  \label{fig:pspic}
\end{figure}

This approach has been shown to work for simple construction steps. Output diagram for the steps above is shown in Figure 2.

\begin{figure}[H]
  \begin{center}
    \includegraphics[scale=0.5]{image.png}
  \end{center}
  \caption{Graphical visualization of the sample alignment}
  \label{fig:pspic}
\end{figure}

% \begin{enumerate}
% \item English-to-Metalanguage and Hindi-to-Metalanguage sentence pairs have been collected from NCERT textbooks to be used in bootstrap corpus.
% \item The approach has been shown to work for simple construction steps. Output diagram for the steps above is shown in Figure 1.
\begin{figure}[H]
  \begin{center}
    \includegraphics[scale=0.5]{triangle.png}
  \end{center}
  \caption{Constructed Triangle}
  \label{fig:pspic}
\end{figure}
%\end{enumerate}

\section{Results}
\begin{enumerate}
\item Number of sentences in the corpus: 360 each in English-to-Metalanguage and Hindi-to-Metalanguage corpus 
\item A sample prototype implementation that demonstrates the performance of the system for simple construction steps of drawing line segments and arcs.
\item Number of unique tokens in each of the three languages:\\
\begin{table}[h]
\smallskip
\begin{center}
\begin{tabular}{cc}
\hline
\bf{Language} & \bf{Number of unique tokens}\\[0.2cm]\hline
English & 181+\\
Hindi & 169+\\
Metalanguage & 110+\\
\hline
\end{tabular}
\caption{Unique tokens in different languages}
\end{center}
\end{table}
\end{enumerate}

\subsection{Difficulties}
\begin{itemize}
\item {\bf Anaphoras}
Dealing with anaphoras like ``this'', ``it'', ``previous'', ``last'' etc in sentences like ``Mark any point M on it'', ``{\dn ek \7{s}EvDAjnk E/>yA l\?kr EpCl\? crZ vAl\? cAp ko Eb\306w\7{d}} A {\dn pr kAV\?{\qva}.}'' etc
\item {\bf Underspecified Parameters}
We also need to provide for unspecified radii, lengths and anlge measures e.g. ``With A and B as centers and a suitable radius, draw two arcs interseting eachother at point C''
\item {\bf Probabilistic Mapping}
Since the mapping is statistical in nature, there might be various close alignments for the same source-language word. This forces us to resort to try out different possible alignments and look for the one that fits e.g. for the sentence ``Construct AB of length 7.8cm'', we get the following alignments with their corresponding probabilites (we assume that probabilites of word-wise alignment are independent of eachother)
\begin{table}[H]
\begin{center}
\begin{tabular}{lc}
\hline
\bf{Mapped meta-language sentence} & \bf{Probability}\\\hline
construct AB any length 7.8cm & 0.716853\\
construct AB lineSegment length 7.8cm & 0.21081\\
construct AB angle length 7.8cm & 0.0723206\\
construct AB center length 7.8cm & 1.90645e-06\\
\hline
\end{tabular}
\caption{Map to possible metalanguage sentences alongwith their probabilities}
\end{center}
\end{table}
\end{itemize}

\section{What needs to be done}
\begin{enumerate}
\item Enrich the corpus to cover larger domains of expressions e.g. having larger number of primitive steps, providing for higher-level primitives, specifying relative distances, dealing with anaphoras and references
\item Expand the functionality of the system to work for all kinds of construction steps claimed so far
\item Deploy the system on a webserver to demonstrate its functionality and work towards making it more robust
\item In order to capture colloquial (non-academic) ways of expressing construction steps, we need to develop a user interface that augments the corpus with input sentences
\end{enumerate}

\nocite{schreck2012geometric}
\nocite{gulwani2011synthesizing}
\nocite{ahmed2012can}
\nocite{itzhaky2012solving}
\nocite{zettlemoyer2012learning}
\nocite{och2003systematic}

\bibliography{report}{}
\bibliographystyle{plain-annote}
\end{document}
